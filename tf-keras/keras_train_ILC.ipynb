{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return awkward.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessData(data):\n",
    "    # remove low-momentum jets\n",
    "    good = data[data.p > 25]\n",
    "    for particle_idx in range(50):\n",
    "        # change to deltaEta (rel to jet axis)\n",
    "        good.loc[:, \"p\" + str(particle_idx+1)+\"eta\"] = np.abs(good.eta - good[\"p\" + str(particle_idx+1)+\"eta\"])\n",
    "        # change to deltaPhi (rel to jet axis)\n",
    "        good.loc[:, \"p\" + str(particle_idx+1)+\"phi\"] -= good.phi \n",
    "        good.loc[good[\"p\" + str(particle_idx+1)+\"phi\"] <= -np.pi, \"p\" + str(particle_idx+1)+\"phi\"] += 2*np.pi\n",
    "        good.loc[np.pi <= good[\"p\" + str(particle_idx+1)+\"phi\"], \"p\" + str(particle_idx+1)+\"phi\"] -= 2*np.pi\n",
    "        # change to Pfrac (rel to jet p)\n",
    "        good.loc[:, \"p\" + str(particle_idx+1)+\"p\"] /= good.p \n",
    "    return good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "class Dataset(object):\n",
    "    def __init__(self, filepath, feature_dict = {}, label='label', pad_len=50, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict)==0:\n",
    "            feature_dict['points'] = ['eta', 'phi']\n",
    "            feature_dict['features'] = ['p', 'eta', 'phi']\n",
    "            feature_dict['mask'] = ['p']\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "        data = pd.read_csv(self.filepath)\n",
    "        # let's start with only \"bb\" and \"uu\"\n",
    "        data = data[data.sampleType.isin([\"bb\", \"uu\"])]\n",
    "        # change jet values to relative ones\n",
    "        data = preProcessData(data)\n",
    "        # we need to one-hot encode the labels\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit_transform(data[self.label].to_numpy())\n",
    "        # binary encode\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "        onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "        self._label = onehot_encoded\n",
    "        \n",
    "        # each particle has its own index (e.g. eta17), but we want to collect\n",
    "        # them all in array with the same name (i.e., eta)\n",
    "        for k in self.feature_dict:\n",
    "            cols = self.feature_dict[k]\n",
    "            if not isinstance(cols, (list, tuple)):\n",
    "                cols = [cols]\n",
    "            self._values[k] = np.zeros((len(self._label), self.pad_len, len(cols)))\n",
    "#             arrs = []\n",
    "            for col_idx, col in enumerate(cols):\n",
    "                # the data for all particles for this column\n",
    "#                 colArray = []\n",
    "                for particle_idx in range(self.pad_len):\n",
    "                    colname = \"p\" + str(particle_idx+1) + col\n",
    "                    self._values[k][:, particle_idx, col_idx] = data[colname].to_numpy()\n",
    "#             self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-13 18:57:35,031] INFO: Start loading file ../data/ILD_ParticleNet_MC_tagging_train.csv\n",
      "/home/jstrube/.local/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "[2021-02-13 18:57:49,227] INFO: Finished loading file ../data/ILD_ParticleNet_MC_tagging_train.csv\n",
      "[2021-02-13 18:57:49,246] INFO: Start loading file ../data/ILD_ParticleNet_MC_tagging_val.csv\n",
      "/home/jstrube/.local/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "[2021-02-13 18:57:51,119] INFO: Finished loading file ../data/ILD_ParticleNet_MC_tagging_val.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset('../data/ILD_ParticleNet_MC_tagging_train.csv', label=\"sampleType\", data_format='channel_last')\n",
    "val_dataset = Dataset('../data/ILD_ParticleNet_MC_tagging_val.csv', label=\"sampleType\", data_format='channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'points': (50, 2), 'features': (50, 3), 'mask': (50, 1)}\n",
      "(157071, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_dataset.y.shape[1]\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "\n",
    "print(num_classes)\n",
    "print(input_shapes)\n",
    "print(train_dataset[\"points\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.50169e+05, 5.98800e+03, 7.45000e+02, 1.05000e+02, 2.50000e+01,\n",
       "        1.50000e+01, 1.10000e+01, 4.00000e+00, 5.00000e+00, 4.00000e+00]),\n",
       " array([1.82610898e-07, 3.62337774e-01, 7.24675366e-01, 1.08701296e+00,\n",
       "        1.44935055e+00, 1.81168814e+00, 2.17402573e+00, 2.53636333e+00,\n",
       "        2.89870092e+00, 3.26103851e+00, 3.62337610e+00]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_dataset[\"points\"][:, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "# model_type = 'particle_net' # choose between 'particle_net' and 'particle_net_lite'\n",
    "num_classes = train_dataset.y.shape[1]\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 5:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 10:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-13 19:02:00,770] INFO: Learning rate: 0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 50, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.not_equal_1 (TFOpLambda (None, 50, 1)        0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_2 (TFOpLambda)          (None, 50, 1)        0           tf.math.not_equal_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.equal_1 (TFOpLambda)    (None, 50, 1)        0           tf.cast_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_3 (TFOpLambda)          (None, 50, 1)        0           tf.math.equal_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_8 (TFOpLambda) (None, 50, 1)        0           tf.cast_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 50, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_2 (TFOpLambda)      (None, 50, 2)        0           tf.math.multiply_8[0][0]         \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 50, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_4 (TFOpL (None, 2, 50)        0           tf.math.add_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_7 (TFOpLambda)   (None, 50, 1, 3)     0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_9 (TFOpLambda) (None, 50, 2)        0           tf.math.add_2[0][0]              \n",
      "                                                                 tf.math.add_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_2 (TFOpLambda) (None, 50, 50)       0           tf.math.add_2[0][0]              \n",
      "                                                                 tf.compat.v1.transpose_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_10 (TFOpLambda (None, 50, 2)        0           tf.math.add_2[0][0]              \n",
      "                                                                 tf.math.add_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 50, 1, 3)     12          tf.expand_dims_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_4 (TFOpLambd (None, 50, 1)        0           tf.math.multiply_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_11 (TFOpLambda (None, 50, 50)       0           tf.linalg.matmul_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_5 (TFOpLambd (None, 50, 1)        0           tf.math.multiply_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_3 (TFOpLam (None, 50, 3)        0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_4 (TFOpLambda) (None, 50, 50)       0           tf.math.reduce_sum_4[0][0]       \n",
      "                                                                 tf.math.multiply_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_5 (TFOpL (None, 1, 50)        0           tf.math.reduce_sum_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_2 (TFOpLambd (3,)                 0           tf.compat.v1.squeeze_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_4 (TFOpLam (None, 50, 50)       0           tf.math.subtract_4[0][0]         \n",
      "                                                                 tf.compat.v1.transpose_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli ()                   0           tf.compat.v1.shape_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.negative_2 (TFOpLambda) (None, 50, 50)       0           tf.__operators__.add_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_2 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k_2 (TFOpLambda)    TopKV2(values=(None, 0           tf.math.negative_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_2 (TFOpLambda)       (None, 1, 1, 1)      0           tf.range_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 50, 7)        0           tf.math.top_k_2[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_4 (TFOpLambda)          (None, 50, 7, 1)     0           tf.reshape_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_8 (TFOpLambda)   (None, 50, 7, 1)     0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_9 (TFOpLambda)   (None, 50, 1, 3)     0           tf.compat.v1.squeeze_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_4 (TFOpLambda)        (None, 50, 7, 2)     0           tf.tile_4[0][0]                  \n",
      "                                                                 tf.expand_dims_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_5 (TFOpLambda)          (None, 50, 7, 3)     0           tf.expand_dims_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.gather_nd_2 (TFOpL (None, 50, 7, 3)     0           tf.compat.v1.squeeze_3[0][0]     \n",
      "                                                                 tf.concat_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_5 (TFOpLambda) (None, 50, 7, 3)     0           tf.compat.v1.gather_nd_2[0][0]   \n",
      "                                                                 tf.tile_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_5 (TFOpLambda)        (None, 50, 7, 6)     0           tf.tile_5[0][0]                  \n",
      "                                                                 tf.math.subtract_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 50, 7, 32)    192         tf.concat_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 50, 7, 32)    128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 50, 7, 32)    0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 50, 7, 32)    1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 50, 7, 32)    128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 50, 7, 32)    0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_10 (TFOpLambda)  (None, 50, 1, 3)     0           tf.compat.v1.squeeze_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 50, 7, 32)    1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 50, 1, 32)    96          tf.expand_dims_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 50, 7, 32)    128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 50, 1, 32)    128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 50, 7, 32)    0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_4 (TFOpLam (None, 50, 32)       0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_3 (TFOpLamb (None, 50, 32)       0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 50, 32)       0           tf.compat.v1.squeeze_4[0][0]     \n",
      "                                                                 tf.math.reduce_mean_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 50, 32)       0           tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_3 (TFOpLambda)      (None, 50, 32)       0           tf.math.multiply_8[0][0]         \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_6 (TFOpL (None, 32, 50)       0           tf.math.add_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_12 (TFOpLambda (None, 50, 32)       0           tf.math.add_3[0][0]              \n",
      "                                                                 tf.math.add_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_3 (TFOpLambda) (None, 50, 50)       0           tf.math.add_3[0][0]              \n",
      "                                                                 tf.compat.v1.transpose_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_13 (TFOpLambda (None, 50, 32)       0           tf.math.add_3[0][0]              \n",
      "                                                                 tf.math.add_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_6 (TFOpLambd (None, 50, 1)        0           tf.math.multiply_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_14 (TFOpLambda (None, 50, 50)       0           tf.linalg.matmul_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_7 (TFOpLambd (None, 50, 1)        0           tf.math.multiply_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_6 (TFOpLambda) (None, 50, 50)       0           tf.math.reduce_sum_6[0][0]       \n",
      "                                                                 tf.math.multiply_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_7 (TFOpL (None, 1, 50)        0           tf.math.reduce_sum_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_3 (TFOpLambd (3,)                 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 50, 50)       0           tf.math.subtract_6[0][0]         \n",
      "                                                                 tf.compat.v1.transpose_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli ()                   0           tf.compat.v1.shape_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.negative_3 (TFOpLambda) (None, 50, 50)       0           tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_3 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k_3 (TFOpLambda)    TopKV2(values=(None, 0           tf.math.negative_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_3 (TFOpLambda)       (None, 1, 1, 1)      0           tf.range_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 50, 7)        0           tf.math.top_k_3[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_6 (TFOpLambda)          (None, 50, 7, 1)     0           tf.reshape_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_11 (TFOpLambda)  (None, 50, 7, 1)     0           tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_12 (TFOpLambda)  (None, 50, 1, 32)    0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_6 (TFOpLambda)        (None, 50, 7, 2)     0           tf.tile_6[0][0]                  \n",
      "                                                                 tf.expand_dims_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_7 (TFOpLambda)          (None, 50, 7, 32)    0           tf.expand_dims_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.gather_nd_3 (TFOpL (None, 50, 7, 32)    0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf.concat_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_7 (TFOpLambda) (None, 50, 7, 32)    0           tf.compat.v1.gather_nd_3[0][0]   \n",
      "                                                                 tf.tile_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_7 (TFOpLambda)        (None, 50, 7, 64)    0           tf.tile_7[0][0]                  \n",
      "                                                                 tf.math.subtract_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 50, 7, 64)    4096        tf.concat_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 50, 7, 64)    256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 50, 7, 64)    0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 50, 7, 64)    4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 50, 7, 64)    256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 50, 7, 64)    0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_13 (TFOpLambda)  (None, 50, 1, 32)    0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 50, 7, 64)    4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 50, 1, 64)    2048        tf.expand_dims_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 50, 7, 64)    256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 50, 1, 64)    256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 50, 7, 64)    0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_5 (TFOpLam (None, 50, 64)       0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_4 (TFOpLamb (None, 50, 64)       0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 50, 64)       0           tf.compat.v1.squeeze_5[0][0]     \n",
      "                                                                 tf.math.reduce_mean_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 50, 64)       0           tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_15 (TFOpLambda (None, 50, 64)       0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf.cast_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_5 (TFOpLamb (None, 64)           0           tf.math.multiply_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        tf.math.reduce_mean_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            258         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,798\n",
      "Trainable params: 26,024\n",
      "Non-trainable params: 774\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = 'ILC_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-13 21:06:24,035] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "127/154 [=======================>......] - ETA: 27s - loss: 0.5513 - accuracy: 0.7152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-bd52a4b3a050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(train_dataset.X, train_dataset.y,\n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#           epochs=epochs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# --- train only for 1 epoch here for demonstration ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=25, # --- train only for 1 epoch here for demonstration ---\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
