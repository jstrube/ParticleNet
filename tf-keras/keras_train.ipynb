{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jstrube/.local/lib/python3.8/site-packages/awkward0/__init__.py:12: FutureWarning: Consider switching from 'awkward0' to 'awkward', since the new interface became the default in 2020.\n",
      "\n",
      "    pip install -U awkward\n",
      "\n",
      "In Python:\n",
      "\n",
      "    >>> import awkward as ak\n",
      "    >>> new_style_array = ak.from_awkward0(old_style_array)\n",
      "    >>> old_style_array = ak.to_awkward0(new_style_array)\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import awkward0 as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_arrays(a, keys, axis=-1):\n",
    "    flat_arr = np.stack([a[k].flatten() for k in keys], axis=axis)\n",
    "    return ak.JaggedArray.fromcounts(a[keys[0]].counts, flat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(a, maxlen, value=0., dtype='float32'):\n",
    "    x = (np.ones((len(a), maxlen)) * value).astype(dtype)\n",
    "    for idx, s in enumerate(a):\n",
    "        if not len(s):\n",
    "            continue\n",
    "        trunc = s[:maxlen].astype(dtype)\n",
    "        x[idx, :len(trunc)] = trunc\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "\n",
    "    def __init__(self, filepath, feature_dict = {}, label='label', pad_len=100, data_format='channel_first'):\n",
    "        self.filepath = filepath\n",
    "        self.feature_dict = feature_dict\n",
    "        if len(feature_dict)==0:\n",
    "            feature_dict['points'] = ['part_etarel', 'part_phirel']\n",
    "            feature_dict['features'] = ['part_pt_log', 'part_e_log', 'part_etarel', 'part_phirel']\n",
    "            feature_dict['mask'] = ['part_pt_log']\n",
    "        self.label = label\n",
    "        self.pad_len = pad_len\n",
    "        assert data_format in ('channel_first', 'channel_last')\n",
    "        self.stack_axis = 1 if data_format=='channel_first' else -1\n",
    "        self._values = {}\n",
    "        self._label = None\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        logging.info('Start loading file %s' % self.filepath)\n",
    "        counts = None\n",
    "        with ak.load(self.filepath) as a:\n",
    "            self._label = a[self.label]\n",
    "            for k in self.feature_dict:\n",
    "                cols = self.feature_dict[k]\n",
    "                if not isinstance(cols, (list, tuple)):\n",
    "                    cols = [cols]\n",
    "                arrs = []\n",
    "                for col in cols:\n",
    "                    if counts is None:\n",
    "                        counts = a[col].counts\n",
    "                    else:\n",
    "                        assert np.array_equal(counts, a[col].counts)\n",
    "                    arrs.append(pad_array(a[col], self.pad_len))\n",
    "                self._values[k] = np.stack(arrs, axis=self.stack_axis)\n",
    "        logging.info('Finished loading file %s' % self.filepath)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key==self.label:\n",
    "            return self._label\n",
    "        else:\n",
    "            return self._values[key]\n",
    "    \n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._values\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._label\n",
    "\n",
    "    def shuffle(self, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        shuffle_indices = np.arange(self.__len__())\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        for k in self._values:\n",
    "            self._values[k] = self._values[k][shuffle_indices]\n",
    "        self._label = self._label[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-05 20:23:20,854] INFO: Start loading file converted/train_file_0.awkd\n",
      "[2021-02-05 20:23:45,899] INFO: Finished loading file converted/train_file_0.awkd\n",
      "[2021-02-05 20:23:45,901] INFO: Start loading file converted/val_file_0.awkd\n",
      "[2021-02-05 20:23:54,502] INFO: Finished loading file converted/val_file_0.awkd\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset('converted/train_file_0.awkd', data_format='channel_last')\n",
    "val_dataset = Dataset('converted/val_file_0.awkd', data_format='channel_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'points': (100, 2), 'features': (100, 4), 'mask': (100, 1)}\n",
      "(1211000, 100, 2)\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_dataset.y.shape[1]\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "\n",
    "print(num_classes)\n",
    "print(input_shapes)\n",
    "print(train_dataset[\"points\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-05 20:23:54,631] INFO: Generating new fontManager, this may take some time...\n",
      "[2021-02-05 20:23:55,506] INFO: Failed to extract font properties from /usr/share/fonts/truetype/noto/NotoColorEmoji.ttf: In FT2Font: Can not load face.  Unknown file format.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.92000e+02, 5.08700e+03, 2.70670e+04, 1.02327e+05, 3.70317e+05,\n",
       "        5.71337e+05, 1.03778e+05, 2.59280e+04, 4.38400e+03, 2.83000e+02]),\n",
       " array([-0.8135103 , -0.65463793, -0.49576563, -0.33689326, -0.17802092,\n",
       "        -0.01914859,  0.13972375,  0.29859608,  0.45746845,  0.61634076,\n",
       "         0.7752131 ], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATY0lEQVR4nO3df6zdd33f8ecLmwBbCfnlupmd7KbCaHUzNYAVzDoEJSU4YcKZRllQWVxkYakJUyc2DTP+yAZDSjoV1qg0bdRYcdBYktLSWI1TY0IitgoHOyMkTTLIJQRiN8RunIRFCGjoe3+cj8nh9nzuPTe599wb5/mQju73+/5+vt/P+/7wed3z/X7PdaoKSZJGeclSNyBJWr4MCUlSlyEhSeoyJCRJXYaEJKlr5VI3sNBOO+20mpqaWuo2JOkF5a677vqbqlo1s37chcTU1BQHDhxY6jYk6QUlybdH1T3dJEnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jru3nEtLVdT229ZsrkfvuIdSza3Xth8JSFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkrrFCIsnDSe5NcneSA612SpK9SR5sH09u9SS5Ksl0knuSvG7oOFva+AeTbBmqv74df7rtm9nmkCRNxnxeSfxKVZ1TVRva+nbgtqpaB9zW1gEuANa1xzbgahg84QOXA28AzgUuH3rSvxp4/9B+m+aYQ5I0Ac/ndNNmYGdb3glcNFS/vgb2ASclOR14O7C3qo5W1RPAXmBT23ZiVe2rqgKun3GsUXNIkiZg3JAo4PNJ7kqyrdVWV9Wjbfm7wOq2vAZ4ZGjfg602W/3giPpsc0iSJmDlmOP+eVUdSvKzwN4k/3d4Y1VVklr49sabowXXNoAzzzxzMduQpBeVsV5JVNWh9vEw8DkG1xQea6eKaB8Pt+GHgDOGdl/barPV146oM8scM/u7pqo2VNWGVatWjfMpSZLGMGdIJPmHSV55bBk4H/grYBdw7A6lLcDNbXkXcEm7y2kj8FQ7ZbQHOD/Jye2C9fnAnrbte0k2truaLplxrFFzSJImYJzTTauBz7W7UlcCn6mqv0iyH7gpyVbg28C72/jdwIXANPB94H0AVXU0yceA/W3cR6vqaFu+FLgOeAVwa3sAXNGZQ5I0AXOGRFU9BPzSiPrjwHkj6gVc1jnWDmDHiPoB4Oxx55AkTYbvuJYkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6xg6JJCuSfDXJn7f1s5LcmWQ6yY1JTmj1l7X16bZ9augYH271ryd5+1B9U6tNJ9k+VB85hyRpMubzSuK3gAeG1q8EPllVrwaeALa2+lbgiVb/ZBtHkvXAxcAvApuA32/BswL4FHABsB54Txs72xySpAkYKySSrAXeAfxRWw/wVuCzbchO4KK2vLmt07af18ZvBm6oqh9W1beAaeDc9piuqoeq6kfADcDmOeaQJE3AuK8k/jvwH4G/a+unAk9W1TNt/SCwpi2vAR4BaNufauN/Up+xT68+2xw/Jcm2JAeSHDhy5MiYn5IkaS5zhkSSfwEcrqq7JtDPc1JV11TVhqrasGrVqqVuR5KOGyvHGPPLwDuTXAi8HDgR+F3gpCQr22/6a4FDbfwh4AzgYJKVwKuAx4fqxwzvM6r++CxzSJImYM5XElX14apaW1VTDC48f7Gqfh24HXhXG7YFuLkt72rrtO1frKpq9Yvb3U9nAeuArwD7gXXtTqYT2hy72j69OSRJE/B83ifxIeCDSaYZXD+4ttWvBU5t9Q8C2wGq6j7gJuB+4C+Ay6rqx+1VwgeAPQzunrqpjZ1tDknSBIxzuuknquoO4I62/BCDO5NmjvkB8Gud/T8OfHxEfTewe0R95BySpMnwHdeSpC5DQpLUZUhIkroMCUlSlyEhSeqa191N0vFgavstS92C9ILhKwlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdc0ZEklenuQrSb6W5L4k/6XVz0pyZ5LpJDcmOaHVX9bWp9v2qaFjfbjVv57k7UP1Ta02nWT7UH3kHJKkyRjnlcQPgbdW1S8B5wCbkmwErgQ+WVWvBp4AtrbxW4EnWv2TbRxJ1gMXA78IbAJ+P8mKJCuATwEXAOuB97SxzDKHJGkC5gyJGni6rb60PQp4K/DZVt8JXNSWN7d12vbzkqTVb6iqH1bVt4Bp4Nz2mK6qh6rqR8ANwOa2T28OSdIEjHVNov3GfzdwGNgLfBN4sqqeaUMOAmva8hrgEYC2/Sng1OH6jH169VNnmWNmf9uSHEhy4MiRI+N8SpKkMYwVElX146o6B1jL4Df/f7KYTc1XVV1TVRuqasOqVauWuh1JOm7M6+6mqnoSuB14I3BSkpVt01rgUFs+BJwB0La/Cnh8uD5jn1798VnmkCRNwDh3N61KclJbfgXwNuABBmHxrjZsC3BzW97V1mnbv1hV1eoXt7ufzgLWAV8B9gPr2p1MJzC4uL2r7dObQ5I0ASvnHsLpwM52F9JLgJuq6s+T3A/ckOS/Al8Frm3jrwU+nWQaOMrgSZ+qui/JTcD9wDPAZVX1Y4AkHwD2ACuAHVV1XzvWhzpzSJImYM6QqKp7gNeOqD/E4PrEzPoPgF/rHOvjwMdH1HcDu8edQ5I0Gb7jWpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlS15whkeSMJLcnuT/JfUl+q9VPSbI3yYPt48mtniRXJZlOck+S1w0da0sb/2CSLUP11ye5t+1zVZLMNockaTLGeSXxDPDvq2o9sBG4LMl6YDtwW1WtA25r6wAXAOvaYxtwNQye8IHLgTcA5wKXDz3pXw28f2i/Ta3em0OSNAFzhkRVPVpV/6ct/z/gAWANsBnY2YbtBC5qy5uB62tgH3BSktOBtwN7q+poVT0B7AU2tW0nVtW+qirg+hnHGjWHJGkC5nVNIskU8FrgTmB1VT3aNn0XWN2W1wCPDO12sNVmqx8cUWeWOWb2tS3JgSQHjhw5Mp9PSZI0i7FDIsnPAH8C/Luq+t7wtvYKoBa4t58y2xxVdU1VbaiqDatWrVrMNiTpRWWskEjyUgYB8T+q6k9b+bF2qoj28XCrHwLOGNp9bavNVl87oj7bHJKkCRjn7qYA1wIPVNUnhjbtAo7dobQFuHmofkm7y2kj8FQ7ZbQHOD/Jye2C9fnAnrbte0k2trkumXGsUXNIkiZg5Rhjfhn4N8C9Se5utf8EXAHclGQr8G3g3W3bbuBCYBr4PvA+gKo6muRjwP427qNVdbQtXwpcB7wCuLU9mGUOSdIEzBkSVfW/gXQ2nzdifAGXdY61A9gxon4AOHtE/fFRc0iSJsN3XEuSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6pozJJLsSHI4yV8N1U5JsjfJg+3jya2eJFclmU5yT5LXDe2zpY1/MMmWofrrk9zb9rkqSWabQ5I0OeO8krgO2DSjth24rarWAbe1dYALgHXtsQ24GgZP+MDlwBuAc4HLh570rwbeP7TfpjnmkCRNyMq5BlTVl5JMzShvBt7SlncCdwAfavXrq6qAfUlOSnJ6G7u3qo4CJNkLbEpyB3BiVe1r9euBi4BbZ5lD0jxNbb9lSeZ9+Ip3LMm8WjhzhkTH6qp6tC1/F1jdltcAjwyNO9hqs9UPjqjPNoeOA0v1pCVpfp73hev2qqEWoJfnPEeSbUkOJDlw5MiRxWxFkl5UnmtIPNZOI9E+Hm71Q8AZQ+PWttps9bUj6rPN8fdU1TVVtaGqNqxateo5fkqSpJmea0jsAo7dobQFuHmofkm7y2kj8FQ7ZbQHOD/Jye2C9fnAnrbte0k2truaLplxrFFzSJImZM5rEkn+J4MLyKclOcjgLqUrgJuSbAW+Dby7Dd8NXAhMA98H3gdQVUeTfAzY38Z99NhFbOBSBndQvYLBBetbW703hyRpQsa5u+k9nU3njRhbwGWd4+wAdoyoHwDOHlF/fNQckqTJ8R3XkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSepaudQNaGlNbb9lqVvQcWwpf74evuIdSzb38cRXEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldyz4kkmxK8vUk00m2L3U/kvRisqzfJ5FkBfAp4G3AQWB/kl1Vdf/SdrawfK+CtPCW6t/V8fb+jOX+SuJcYLqqHqqqHwE3AJuXuCdJetFY1q8kgDXAI0PrB4E3zByUZBuwra0+neTrCzD3acDfLMBxFpp9zd9y7c2+5m+59vaTvnLlEnfy0+bz9frHo4rLPSTGUlXXANcs5DGTHKiqDQt5zIVgX/O3XHuzr/lbrr0dz30t99NNh4AzhtbXtpokaQKWe0jsB9YlOSvJCcDFwK4l7kmSXjSW9emmqnomyQeAPcAKYEdV3Teh6Rf09NUCsq/5W6692df8Ldfejtu+UlUL0Ygk6Ti03E83SZKWkCEhSeoyJJokpyTZm+TB9vHkzrjfTnJfkgeSXJUky6SvM5N8vvV1f5Kp5dBXG3tikoNJfm8xe5pPb0nOSfLl9r28J8m/XsR+Zv3TMkleluTGtv3Oxf7ezaOvD7afpXuS3JZk5H30k+5raNy/SlJJJnbr6Ti9JXl3+7rdl+Qzy6Gv9vxwe5Kvtu/nhWMfvKp8DK7L/DawvS1vB64cMeafAX/J4CL6CuDLwFuWuq+27Q7gbW35Z4B/sBz6att/F/gM8HvL6Hv5GmBdW/5HwKPASYvQywrgm8DPAycAXwPWzxhzKfAHbfli4MYJfI3G6etXjv0cAb+5XPpq414JfAnYB2yY0M/VOF+zdcBXgZPb+s8uk76uAX6zLa8HHh73+L6SeNZmYGdb3glcNGJMAS9n8I14GfBS4LGl7ivJemBlVe0FqKqnq+r7S91X6+31wGrg84vcz7A5e6uqb1TVg235r4HDwKpF6GWcPy0z3O9ngfMW+xXqOH1V1e1DP0f7GLxPabGN+6d4PgZcCfxgAj3Np7f3A5+qqicAqurwMumrgBPb8quAvx734IbEs1ZX1aNt+bsMnth+SlV9GbidwW+djwJ7quqBpe6LwW/FTyb50/Zy8r+1P464pH0leQnwO8B/WOReZhrna/YTSc5lEPzfXIReRv1pmTW9MVX1DPAUcOoi9DLfvoZtBW5d1I4G5uwryeuAM6pq0n/Bb5yv2WuA1yT5yyT7kmxaJn39Z+C9SQ4Cu4F/O+7Bl/X7JBZaki8APzdi00eGV6qqkvy9e4OTvBr4BZ79jWpvkjdV1f9ayr4YfB/fBLwW+A5wI/AbwLVL3NelwO6qOrjQvxgvQG/HjnM68GlgS1X93YI2eZxI8l5gA/DmZdDLS4BPMPj5Xo5WMjjl9BYGzxNfSvJPq+rJpWwKeA9wXVX9TpI3Ap9OcvY4P/MvqpCoql/tbUvyWJLTq+rR9sQx6mXivwT2VdXTbZ9bgTcCzyskFqCvg8DdVfVQ2+fPgI08z5BYgL7eCLwpyaUMrpOckOTpqnre/y/IAvRGkhOBW4CPVNW+59tTxzh/WubYmINJVjI4HfD4IvUzn75I8qsMgvfNVfXDRe5pnL5eCZwN3NF+8fg5YFeSd1bVgSXuDQb/Fu+sqr8FvpXkGwxCY/8S97UV2ASDMyJJXs7gj//NeTrM003P2gVsactbgJtHjPkO8OYkK5O8lMFvVot9ummcvvYDJyU5dk79rcBi/58bc/ZVVb9eVWdW1RSDU07XL0RALERvGfyZl8+1nj67iL2M86dlhvt9F/DFalcYl7KvJK8F/hB454TOrc/ZV1U9VVWnVdVU+7na1/pb7ICYs7fmzxi8iiDJaQxOPz20DPr6DnBe6+sXGFxbPTLW0Rf7yvsL5cHgHPBtwIPAF4BTWn0D8Ef17F0Ef8ggGO4HPrEc+mrrbwPuAe4FrgNOWA59DY3/DSZ3d9M438v3An8L3D30OGeR+rkQ+AaDax4fabWPMnhyo/2D/WNgGvgK8PMT+jrN1dcXGNyYcezrs2s59DVj7B1M6O6mMb9mYXA67P72b/HiZdLXegZ3Zn6tfS/PH/fY/lkOSVKXp5skSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVLX/wcI3p5x5yTGAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_dataset[\"points\"][:, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tf_keras_model import get_particle_net, get_particle_net_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'particle_net_lite' # choose between 'particle_net' and 'particle_net_lite'\n",
    "num_classes = train_dataset.y.shape[1]\n",
    "input_shapes = {k:train_dataset[k].shape[1:] for k in train_dataset.X}\n",
    "if 'lite' in model_type:\n",
    "    model = get_particle_net_lite(num_classes, input_shapes)\n",
    "else:\n",
    "    model = get_particle_net(num_classes, input_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 1024 if 'lite' in model_type else 384\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 10:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 20:\n",
    "        lr *= 0.01\n",
    "    logging.info('Learning rate: %f'%lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-02-05 20:23:57,921] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ParticleNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.not_equal (TFOpLambda)  (None, 100, 1)       0           mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 100, 1)       0           tf.math.not_equal[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.equal (TFOpLambda)      (None, 100, 1)       0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_1 (TFOpLambda)          (None, 100, 1)       0           tf.math.equal[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 100, 1)       0           tf.cast_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add (TFOpLambda)        (None, 100, 2)       0           tf.math.multiply[0][0]           \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 2, 100)       0           tf.math.add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 100, 1, 4)    0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 100, 2)       0           tf.math.add[0][0]                \n",
      "                                                                 tf.math.add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul (TFOpLambda)   (None, 100, 100)     0           tf.math.add[0][0]                \n",
      "                                                                 tf.compat.v1.transpose[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 100, 2)       0           tf.math.add[0][0]                \n",
      "                                                                 tf.math.add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_fts_bn (BatchNormal (None, 100, 1, 4)    16          tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 100, 1)       0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 100, 100)     0           tf.linalg.matmul[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 100, 1)       0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 100, 4)       0           ParticleNet_fts_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 100, 100)     0           tf.math.reduce_sum[0][0]         \n",
      "                                                                 tf.math.multiply_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 1, 100)       0           tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (3,)                 0           tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 100, 100)     0           tf.math.subtract[0][0]           \n",
      "                                                                 tf.compat.v1.transpose_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.negative (TFOpLambda)   (None, 100, 100)     0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.range (TFOpLambda)           (None,)              0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k (TFOpLambda)      TopKV2(values=(None, 0           tf.math.negative[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 1, 1, 1)      0           tf.range[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 100, 7)       0           tf.math.top_k[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile (TFOpLambda)            (None, 100, 7, 1)    0           tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda)   (None, 100, 7, 1)    0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_2 (TFOpLambda)   (None, 100, 1, 4)    0           tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 100, 7, 2)    0           tf.tile[0][0]                    \n",
      "                                                                 tf.expand_dims_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_1 (TFOpLambda)          (None, 100, 7, 4)    0           tf.expand_dims_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.gather_nd (TFOpLam (None, 100, 7, 4)    0           tf.compat.v1.squeeze[0][0]       \n",
      "                                                                 tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 100, 7, 4)    0           tf.compat.v1.gather_nd[0][0]     \n",
      "                                                                 tf.tile_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 100, 7, 8)    0           tf.tile_1[0][0]                  \n",
      "                                                                 tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv0 (Co (None, 100, 7, 32)   256         tf.concat_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn0 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act0 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv1 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn1 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act1 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_3 (TFOpLambda)   (None, 100, 1, 4)    0           tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_conv2 (Co (None, 100, 7, 32)   1024        ParticleNet_EdgeConv0_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_conv ( (None, 100, 1, 32)   128         tf.expand_dims_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_bn2 (Batc (None, 100, 7, 32)   128         ParticleNet_EdgeConv0_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_bn (Ba (None, 100, 1, 32)   128         ParticleNet_EdgeConv0_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_act2 (Act (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_1 (TFOpLam (None, 100, 32)      0           ParticleNet_EdgeConv0_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 100, 32)      0           ParticleNet_EdgeConv0_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 100, 32)      0           tf.compat.v1.squeeze_1[0][0]     \n",
      "                                                                 tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv0_sc_act (A (None, 100, 32)      0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.add_1 (TFOpLambda)      (None, 100, 32)      0           tf.math.multiply[0][0]           \n",
      "                                                                 ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 32, 100)      0           tf.math.add_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 100, 32)      0           tf.math.add_1[0][0]              \n",
      "                                                                 tf.math.add_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_1 (TFOpLambda) (None, 100, 100)     0           tf.math.add_1[0][0]              \n",
      "                                                                 tf.compat.v1.transpose_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 100, 32)      0           tf.math.add_1[0][0]              \n",
      "                                                                 tf.math.add_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_2 (TFOpLambd (None, 100, 1)       0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_6 (TFOpLambda) (None, 100, 100)     0           tf.linalg.matmul_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_3 (TFOpLambd (None, 100, 1)       0           tf.math.multiply_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_2 (TFOpLambda) (None, 100, 100)     0           tf.math.reduce_sum_2[0][0]       \n",
      "                                                                 tf.math.multiply_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_3 (TFOpL (None, 1, 100)       0           tf.math.reduce_sum_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (3,)                 0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 100, 100)     0           tf.math.subtract_2[0][0]         \n",
      "                                                                 tf.compat.v1.transpose_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.negative_1 (TFOpLambda) (None, 100, 100)     0           tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_1 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k_1 (TFOpLambda)    TopKV2(values=(None, 0           tf.math.negative_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_1 (TFOpLambda)       (None, 1, 1, 1)      0           tf.range_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 100, 7)       0           tf.math.top_k_1[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_2 (TFOpLambda)          (None, 100, 7, 1)    0           tf.reshape_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_4 (TFOpLambda)   (None, 100, 7, 1)    0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_5 (TFOpLambda)   (None, 100, 1, 32)   0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_2 (TFOpLambda)        (None, 100, 7, 2)    0           tf.tile_2[0][0]                  \n",
      "                                                                 tf.expand_dims_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile_3 (TFOpLambda)          (None, 100, 7, 32)   0           tf.expand_dims_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.gather_nd_1 (TFOpL (None, 100, 7, 32)   0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "                                                                 tf.concat_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_3 (TFOpLambda) (None, 100, 7, 32)   0           tf.compat.v1.gather_nd_1[0][0]   \n",
      "                                                                 tf.tile_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (None, 100, 7, 64)   0           tf.tile_3[0][0]                  \n",
      "                                                                 tf.math.subtract_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv0 (Co (None, 100, 7, 64)   4096        tf.concat_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn0 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv0[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act0 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv1 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn1 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act1 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_6 (TFOpLambda)   (None, 100, 1, 32)   0           ParticleNet_EdgeConv0_sc_act[0][0\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_conv2 (Co (None, 100, 7, 64)   4096        ParticleNet_EdgeConv1_act1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_conv ( (None, 100, 1, 64)   2048        tf.expand_dims_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_bn2 (Batc (None, 100, 7, 64)   256         ParticleNet_EdgeConv1_conv2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_bn (Ba (None, 100, 1, 64)   256         ParticleNet_EdgeConv1_sc_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_act2 (Act (None, 100, 7, 64)   0           ParticleNet_EdgeConv1_bn2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_2 (TFOpLam (None, 100, 64)      0           ParticleNet_EdgeConv1_sc_bn[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 100, 64)      0           ParticleNet_EdgeConv1_act2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 100, 64)      0           tf.compat.v1.squeeze_2[0][0]     \n",
      "                                                                 tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ParticleNet_EdgeConv1_sc_act (A (None, 100, 64)      0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_7 (TFOpLambda) (None, 100, 64)      0           ParticleNet_EdgeConv1_sc_act[0][0\n",
      "                                                                 tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_2 (TFOpLamb (None, 64)           0           tf.math.multiply_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        tf.math.reduce_mean_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,898\n",
      "Trainable params: 26,122\n",
      "Non-trainable params: 776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "import os\n",
    "save_dir = 'model_checkpoints'\n",
    "model_name = '%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=False)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "progress_bar = keras.callbacks.ProgbarLogger()\n",
    "callbacks = [checkpoint, lr_scheduler, progress_bar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-12-31 18:48:35,890] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "      0/Unknown - 2528s 0s/sample - loss: 0.2830 - accuracy: 0.8841\n",
      "Epoch 00001: saving model to model_checkpoints/particle_net_lite_model.001.h5\n",
      "1183/1183 [==============================] - 2682s 2s/sample - loss: 0.2528 - accuracy: 0.8970 - val_loss: 0.1916 - val_accuracy: 0.9224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-12-31 19:33:17,877] INFO: Learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "   0/1183 [..............................] - ETA: 0s - loss: 0.1856 - accuracy: 0.9249"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ef3a9a833917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(train_dataset.X, train_dataset.y,\n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#           epochs=epochs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# --- train only for 1 epoch here for demonstration ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset.shuffle()\n",
    "model.fit(train_dataset.X, train_dataset.y,\n",
    "          batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "          epochs=2, # --- train only for 1 epoch here for demonstration ---\n",
    "          validation_data=(val_dataset.X, val_dataset.y),\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211000, 100, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X[\"points\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211000, 100, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X[\"features\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
